{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast import MLForecast\n",
    "import lightgbm as lgb\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from utils import get_smape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The objective is to predict 3 months of item-level sales data at different store locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a unique_id column\n",
    "df['unique_id'] = 'store' +\\\n",
    "                df['store'].astype(str) + '_' +\\\n",
    "                'item' + df['item'].astype(str)\n",
    "\n",
    "# rename columns\n",
    "df = df.rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df = df[['ds', 'unique_id', 'y']]\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the missing dates\n",
    "df_check = pd.DataFrame()\n",
    "df_check['ds'] = pd.date_range(df.ds.min(), df.ds.max(), freq='D')\n",
    "\n",
    "# merge df and df_check\n",
    "df_new = df.merge(df_check, on='ds')\n",
    "\n",
    "print(f\"There are no missing dates in df: {len(df) == len(df_new)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "fcst = MLForecast(\n",
    "    models=lgb.LGBMRegressor(),\n",
    "    freq='D',\n",
    "    lags=[1, 3], # because of the lagged features the time series become shorter\n",
    "    lag_transforms={\n",
    "        0: [expanding_mean, (rolling_mean, 2, 0)],\n",
    "        1: [expanding_mean],\n",
    "        3: [(rolling_mean, 2, 0)]\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    ")\n",
    "\n",
    "# create a df\n",
    "preprocess_df = fcst.preprocess(df,\n",
    "                                id_col='unique_id',\n",
    "                                time_col='ds',\n",
    "                                target_col='y')\n",
    "preprocess_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your folder with this code should be in your root directory\n",
    "EXPERIMENT_NAME = \"mlflow_example\"\n",
    "EXPERIMENT_ID = mlflow.create_experiment(EXPERIMENT_NAME) \n",
    "\n",
    "for idx, param_num_leaves in enumerate([10, 100, 200]):\n",
    "\n",
    "    # define the model\n",
    "    model = MLForecast(\n",
    "    models=lgb.LGBMRegressor(num_leaves=param_num_leaves),\n",
    "    freq='D',\n",
    "    lags=[1, 3],\n",
    "    lag_transforms={\n",
    "        0: [expanding_mean, (rolling_mean, 2, 0)],\n",
    "        1: [expanding_mean],\n",
    "        3: [(rolling_mean, 2, 0)]\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    "    )\n",
    "    \n",
    "    # perform cross-validation\n",
    "    crossvalidation_df = model.cross_validation(\n",
    "    n_windows=2,\n",
    "    window_size=8,\n",
    "    data=df,\n",
    "    id_col='unique_id',\n",
    "    time_col='ds',\n",
    "    target_col='y',\n",
    "    )\n",
    "    \n",
    "    # evaluate\n",
    "    error = get_smape(crossvalidation_df, model='LGBMRegressor')\n",
    "\n",
    "    RUN_NAME = f\"run_{idx}\"\n",
    "    with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=RUN_NAME) as run:\n",
    "\n",
    "        # track parameters\n",
    "        mlflow.log_param(\"num_leaves\", param_num_leaves)\n",
    "\n",
    "        # track metrics\n",
    "        mlflow.log_metric(\"smape_error\", error)\n",
    "\n",
    "        # track model\n",
    "        mlflow.sklearn.log_model(model, \"LGBMRegressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "\n",
    "# Retrieve Experiment information\n",
    "EXPERIMENT_ID = client.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "df_experiment_info = mlflow.search_runs(EXPERIMENT_ID, order_by=[\"metrics.smape_error ASC\"])\n",
    "\n",
    "# view\n",
    "df_experiment_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the run with the best metric\n",
    "best_run_id = df_experiment_info.loc[0, 'run_id']\n",
    "best_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model of the bext run\n",
    "best_model_path = client.download_artifacts(best_run_id, \"LGBMRegressor\")\n",
    "best_model = mlflow.sklearn.load_model(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the best model\n",
    "best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete runs (DO NOT USE UNLESS CERTAIN)\n",
    "for run_id in df_experiment_info['run_id'].values:\n",
    "    client.delete_run(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete experiment (DO NOT USE UNLESS CERTAIN)\n",
    "client.delete_experiment(EXPERIMENT_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:24:27) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b944e9acf4c4e087eeb4e726fff4a9b3aee96aceb1406b8007a48508552147ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
